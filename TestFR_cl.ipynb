{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-4Xs8Nk69swM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from typing import Tuple, Dict, List, Optional\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "class FaceRecognitionSystem:\n",
        "    def __init__(self, model_dir: str, min_confidence: float = 65.0):\n",
        "        \"\"\"\n",
        "        Initialize the face recognition system.\n",
        "\n",
        "        Args:\n",
        "            model_dir: Directory to store model and related files\n",
        "            min_confidence: Minimum confidence threshold for recognition (0-100)\n",
        "        \"\"\"\n",
        "        self.model_dir = model_dir\n",
        "        self.min_confidence = min_confidence\n",
        "        self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "        self.face_cascade = cv2.CascadeClassifier(\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "        )\n",
        "        self.label_map = {}\n",
        "\n",
        "        # Set up logging\n",
        "        logging.basicConfig(\n",
        "            filename=os.path.join(model_dir, 'face_recognition.log'),\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "\n",
        "    def preprocess_image(self, image: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Preprocess image for better face detection.\n",
        "\n",
        "        Args:\n",
        "            image: Input image\n",
        "\n",
        "        Returns:\n",
        "            Preprocessed image\n",
        "        \"\"\"\n",
        "        # Convert to grayscale if needed\n",
        "        if len(image.shape) == 3:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply histogram equalization for better contrast\n",
        "        image = cv2.equalizeHist(image)\n",
        "\n",
        "        # Apply noise reduction\n",
        "        image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def detect_face(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:\n",
        "        \"\"\"\n",
        "        Detect faces in the image using cascade classifier.\n",
        "\n",
        "        Args:\n",
        "            image: Input image\n",
        "\n",
        "        Returns:\n",
        "            List of face coordinates (x, y, w, h)\n",
        "        \"\"\"\n",
        "        faces = self.face_cascade.detectMultiScale(\n",
        "            image,\n",
        "            scaleFactor=1.1,\n",
        "            minNeighbors=5,\n",
        "            minSize=(30, 30),\n",
        "            flags=cv2.CASCADE_SCALE_IMAGE\n",
        "        )\n",
        "        return faces\n",
        "\n",
        "    def train_model(self, dataset_path: str, test_size: float = 0.2) -> None:\n",
        "        \"\"\"\n",
        "        Train the face recognition model.\n",
        "\n",
        "        Args:\n",
        "            dataset_path: Path to the dataset directory\n",
        "            test_size: Proportion of dataset to use for testing\n",
        "        \"\"\"\n",
        "        faces = []\n",
        "        labels = []\n",
        "        current_label = 0\n",
        "\n",
        "        logging.info(f\"Starting model training with dataset: {dataset_path}\")\n",
        "\n",
        "        # Process dataset\n",
        "        for folder_name in os.listdir(dataset_path):\n",
        "            folder_path = os.path.join(dataset_path, folder_name)\n",
        "            if not os.path.isdir(folder_path):\n",
        "                continue\n",
        "\n",
        "            self.label_map[current_label] = folder_name\n",
        "            logging.info(f\"Processing person: {folder_name}\")\n",
        "\n",
        "            face_count = 0\n",
        "            for filename in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, filename)\n",
        "                try:\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is None:\n",
        "                        logging.warning(f\"Failed to load image: {img_path}\")\n",
        "                        continue\n",
        "\n",
        "                    # Preprocess image\n",
        "                    processed_img = self.preprocess_image(img)\n",
        "\n",
        "                    # Detect faces\n",
        "                    detected_faces = self.detect_face(processed_img)\n",
        "\n",
        "                    for (x, y, w, h) in detected_faces:\n",
        "                        face = processed_img[y:y+h, x:x+w]\n",
        "                        # Resize to ensure consistent size\n",
        "                        face = cv2.resize(face, (160, 160))\n",
        "                        faces.append(face)\n",
        "                        labels.append(current_label)\n",
        "                        face_count += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error processing {img_path}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            logging.info(f\"Processed {face_count} faces for {folder_name}\")\n",
        "            current_label += 1\n",
        "\n",
        "        if not faces:\n",
        "            raise ValueError(\"No faces detected in the dataset!\")\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        faces = np.array(faces)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        # Split dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            faces, labels, test_size=test_size, random_state=42\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        self.recognizer.train(X_train, y_train)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        correct = 0\n",
        "        total = len(X_test)\n",
        "\n",
        "        for face, true_label in zip(X_test, y_test):\n",
        "            pred_label, confidence = self.recognizer.predict(face)\n",
        "            if pred_label == true_label:\n",
        "                correct += 1\n",
        "\n",
        "        accuracy = (correct / total) * 100\n",
        "        logging.info(f\"Model accuracy on test set: {accuracy:.2f}%\")\n",
        "\n",
        "        # Save model and label map\n",
        "        self.save_model()\n",
        "\n",
        "    def save_model(self) -> None:\n",
        "        \"\"\"Save the trained model and label map.\"\"\"\n",
        "        os.makedirs(self.model_dir, exist_ok=True)\n",
        "\n",
        "        model_path = os.path.join(self.model_dir, 'model.yml')\n",
        "        self.recognizer.save(model_path)\n",
        "\n",
        "        label_map_path = os.path.join(self.model_dir, 'label_map.pkl')\n",
        "        with open(label_map_path, 'wb') as f:\n",
        "            pickle.dump(self.label_map, f)\n",
        "\n",
        "        logging.info(f\"Model and label map saved to {self.model_dir}\")\n",
        "\n",
        "    def load_model(self) -> None:\n",
        "        \"\"\"Load the trained model and label map.\"\"\"\n",
        "        model_path = os.path.join(self.model_dir, 'model.yml')\n",
        "        label_map_path = os.path.join(self.model_dir, 'label_map.pkl')\n",
        "\n",
        "        if not os.path.exists(model_path) or not os.path.exists(label_map_path):\n",
        "            raise FileNotFoundError(\"Model or label map not found!\")\n",
        "\n",
        "        self.recognizer.read(model_path)\n",
        "        with open(label_map_path, 'rb') as f:\n",
        "            self.label_map = pickle.load(f)\n",
        "\n",
        "        logging.info(\"Model and label map loaded successfully\")\n",
        "\n",
        "    def recognize_face(self, image_path: str) -> Optional[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Recognize a face in the given image.\n",
        "\n",
        "        Args:\n",
        "            image_path: Path to the image\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (person_name, confidence) or None if no face detected\n",
        "        \"\"\"\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                logging.error(f\"Failed to load image: {image_path}\")\n",
        "                return None\n",
        "\n",
        "            processed_img = self.preprocess_image(img)\n",
        "            faces = self.detect_face(processed_img)\n",
        "\n",
        "            if len(faces) == 0:\n",
        "                logging.warning(\"No faces detected in the image\")\n",
        "                return None\n",
        "\n",
        "            # Use the largest face if multiple detected\n",
        "            largest_face = max(faces, key=lambda rect: rect[2] * rect[3])\n",
        "            x, y, w, h = largest_face\n",
        "\n",
        "            face = processed_img[y:y+h, x:x+w]\n",
        "            face = cv2.resize(face, (160, 160))\n",
        "\n",
        "            label, confidence = self.recognizer.predict(face)\n",
        "\n",
        "            if confidence > self.min_confidence:\n",
        "                person_name = self.label_map.get(label, \"Unknown\")\n",
        "                logging.info(f\"Recognized {person_name} with confidence {confidence:.2f}\")\n",
        "                return person_name, confidence\n",
        "            else:\n",
        "                logging.info(f\"Face detected but confidence too low: {confidence:.2f}\")\n",
        "                return \"Unknown\", confidence\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during recognition: {str(e)}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hu-Tx33-HaD",
        "outputId": "e6555e6b-abe6-42e4-8519-8133c378ee90"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize with the correct paths\n",
        "face_system = FaceRecognitionSystem(\n",
        "    model_dir='/content/drive/MyDrive/Attendance_Model_Mark2/face_recognition_model',\n",
        "    min_confidence=65.0\n",
        ")\n",
        "\n",
        "# Use the verified path from the directory listing\n",
        "verified_path = '/content/drive/MyDrive/Attendance_Training_Mark1'  # adjust this based on the actual path\n",
        "face_system.train_model(verified_path)"
      ],
      "metadata": {
        "id": "1XnnlCmr-34A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First load the trained model\n",
        "face_system.load_model()\n",
        "\n",
        "# Test with a single image\n",
        "test_image_path = '/content/drive/MyDrive/Attendance_Testing_Mark1/23bcs044_test1.jpeg'  # adjust this path to your test image\n",
        "result = face_system.recognize_face(test_image_path)\n",
        "\n",
        "if result:\n",
        "    person_name, confidence = result\n",
        "    print(f\"Person recognized: {person_name}\")\n",
        "    print(f\"Confidence: {confidence:.2f}%\")\n",
        "else:\n",
        "    print(\"No face detected or recognition failed\")\n",
        "\n",
        "# To test multiple images from your test folder:\n",
        "test_folder = '/content/drive/MyDrive/Attendance_Testing_Mark1'  # adjust this path to your test folder\n",
        "\n",
        "for filename in os.listdir(test_folder):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        image_path = os.path.join(test_folder, filename)\n",
        "        print(f\"\\nTesting image: {filename}\")\n",
        "        result = face_system.recognize_face(image_path)\n",
        "\n",
        "        if result:\n",
        "            person_name, confidence = result\n",
        "            print(f\"Person recognized: {person_name}\")\n",
        "            print(f\"Confidence: {confidence:.2f}%\")\n",
        "        else:\n",
        "            print(\"No face detected or recognition failed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4_mkP7aALed",
        "outputId": "520520f0-9459-4a63-bc56-58100ac657a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Person recognized: Dhruv Koli\n",
            "Confidence: 73.83%\n",
            "\n",
            "Testing image: 23bcs028_test.jpeg\n",
            "Person recognized: Dhruv Koli\n",
            "Confidence: 91.69%\n",
            "\n",
            "Testing image: 23bcs044_test1.jpeg\n",
            "Person recognized: Dhruv Koli\n",
            "Confidence: 73.83%\n",
            "\n",
            "Testing image: 23bcs044_test3.jpeg\n",
            "Person recognized: Dhruv Koli\n",
            "Confidence: 85.01%\n",
            "\n",
            "Testing image: 23bcs044_test2.jpeg\n",
            "Person recognized: Barghav Abhilash\n",
            "Confidence: 115.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4wRKWhZUAbvA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}